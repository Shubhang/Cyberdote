{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3DD3_NjMNL6",
        "outputId": "63fbc934-81f1-44f6-9129-a0a5703658ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWb2aRqtaRpm",
        "outputId": "9ddb626c-8701-4d93-e481-256deede0c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (12.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.37.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.22.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.42.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glqc12kpaVZb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LokSopA3aMFk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "import lightgbm as lgbm\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tqdm import tqdm #progress bar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXpuOFGNMhyZ",
        "outputId": "58e76ec6-773c-4c1a-8906-24440d0f340f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fxp4rETrjg3_xbMqCRAGe1PE5pDa11Ps\n",
            "To: /content/combined_datasets.zip\n",
            "100% 305M/305M [00:04<00:00, 71.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1fxp4rETrjg3_xbMqCRAGe1PE5pDa11Ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1chjQlOMjS5",
        "outputId": "f4c5ed91-9c79-4bcc-b895-b7660a34fa6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  combined_datasets.zip\n",
            "   creating: combined_datasets/\n",
            "  inflating: combined_datasets/.DS_Store  \n",
            "  inflating: __MACOSX/combined_datasets/._.DS_Store  \n",
            "  inflating: combined_datasets/combined.csv  \n",
            "  inflating: combined_datasets/balanced.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip combined_datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWlv-eVvMtbG",
        "outputId": "6035e4f2-ffa5-4bae-c0ce-966995498514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/combined_datasets\n"
          ]
        }
      ],
      "source": [
        "%cd combined_datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHsJS_n1M1AJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5iAaWILM3WS"
      },
      "outputs": [],
      "source": [
        "df_balanced = pd.read_csv(\"balanced.csv\")\n",
        "df_combined = pd.read_csv(\"combined.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "C6RzReGMNBx8",
        "outputId": "080d2bbb-77d3-48ee-cec5-0899c8163855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Far too many people see hunters as city folks ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sadly it will not happen because the politiciz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You are correct. Thank you.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>As long as that person's gender identity is no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jackass</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274705</th>\n",
              "      <td>It's not good enough. What arête hey waiting f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274706</th>\n",
              "      <td>Yes, I get a kick when a high school dropout t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274707</th>\n",
              "      <td>Another case of Legislators involving themselv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274708</th>\n",
              "      <td>you just showed that you base your decisions u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274709</th>\n",
              "      <td>mtf1953, maybe. Taxpayers in general can satis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>274710 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment_text  toxicity\n",
              "0       Far too many people see hunters as city folks ...         0\n",
              "1       Sadly it will not happen because the politiciz...         0\n",
              "2                             You are correct. Thank you.         0\n",
              "3       As long as that person's gender identity is no...         0\n",
              "4                                                 Jackass         1\n",
              "...                                                   ...       ...\n",
              "274705  It's not good enough. What arête hey waiting f...         0\n",
              "274706  Yes, I get a kick when a high school dropout t...         1\n",
              "274707  Another case of Legislators involving themselv...         0\n",
              "274708  you just showed that you base your decisions u...         0\n",
              "274709  mtf1953, maybe. Taxpayers in general can satis...         0\n",
              "\n",
              "[274710 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iLnnA8UTPQ-N",
        "outputId": "4fa8c547-aee8-42f5-84a9-3d59fb4936c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Make a mess\".</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It,s made in London where the liberals have tw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:::::The proposal  was passed by  an overwhelm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Just fascinating! It has probably been answer...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Your comment is one of the problems with Eugen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085484</th>\n",
              "      <td>71% of Canadians do not agree with PM Gomer. F...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085485</th>\n",
              "      <td>The law needs to be repealed, what a ridiculou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085486</th>\n",
              "      <td>excellent use of the pastime to cast introspec...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085487</th>\n",
              "      <td>When I look closely at your writing I see the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085488</th>\n",
              "      <td>You want to invent yet another story about why...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2085489 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              comment_text  toxicity\n",
              "0                                           \"Make a mess\".         0\n",
              "1        It,s made in London where the liberals have tw...         0\n",
              "2        :::::The proposal  was passed by  an overwhelm...         0\n",
              "3        \"Just fascinating! It has probably been answer...         0\n",
              "4        Your comment is one of the problems with Eugen...         0\n",
              "...                                                    ...       ...\n",
              "2085484  71% of Canadians do not agree with PM Gomer. F...         0\n",
              "2085485  The law needs to be repealed, what a ridiculou...         1\n",
              "2085486  excellent use of the pastime to cast introspec...         0\n",
              "2085487  When I look closely at your writing I see the ...         0\n",
              "2085488  You want to invent yet another story about why...         0\n",
              "\n",
              "[2085489 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONUOkTffSSZx",
        "outputId": "fa1f9ed2-ed33-491c-94c2-74bc7de41390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.3-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "\n",
        "import catboost as cb\n",
        "\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixZ5hF3HPDr2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6UadX_cYOFm"
      },
      "outputs": [],
      "source": [
        "# train_df, X_test, y_train, y_test= train_test_split(df_balanced.comment_text, df_balanced.toxicity, test_size=0.2, random_state=123)\n",
        "#train_df, val_df= train_test_split(df_balanced[:20000], test_size=0.2, random_state=123)\n",
        "train_df, val_df= train_test_split(df_combined, test_size=0.2, random_state=123)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd0gzckCYrCl",
        "outputId": "0d426e9d-1562-4061-b0a8-81bb5a573e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 194887/1668391 [2:03:19<16:46:18, 24.40it/s]"
          ]
        }
      ],
      "source": [
        "# Load encoder from Tensorflow for LGBM model\n",
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
        "\n",
        "# Embed sentences for the training set\n",
        "X_train = []\n",
        "for r in tqdm(train_df.comment_text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(review_emb)\n",
        "\n",
        "X_train = np.array(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQPkGRu9c_EY"
      },
      "outputs": [],
      "source": [
        "y_train = train_df.toxicity.values\n",
        "\n",
        "# Embed sentences for the validation set\n",
        "Val_test = []\n",
        "for r in tqdm(val_df.comment_text.values):\n",
        "  emb = use(r)\n",
        "  review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  Val_test.append(review_emb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsVCXwLLdBOR"
      },
      "outputs": [],
      "source": [
        "# LGBM\n",
        "\n",
        "# Split data into train and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.1, random_state = 42)\n",
        "\n",
        "# Get the train and test data for the training sequence\n",
        "train_data = lgbm.Dataset(X_train, label=y_train)\n",
        "test_data = lgbm.Dataset(X_test, label=y_test)\n",
        "\n",
        "# Parameters we'll use for the prediction\n",
        "parameters = {\n",
        "    'application': 'binary',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting': 'dart',\n",
        "    'num_leaves': 31,\n",
        "    'feature_fraction': 0.5,\n",
        "    'bagging_fraction': 0.5,\n",
        "    'bagging_freq': 20,\n",
        "    'learning_rate': 0.05,\n",
        "    'verbose': 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7cJKEhodI3w"
      },
      "outputs": [],
      "source": [
        "# Train the classifier\n",
        "classifier = lgbm.train(parameters,\n",
        "                       train_data,\n",
        "                       valid_sets= test_data,\n",
        "                       num_boost_round=5000,\n",
        "                       early_stopping_rounds=100)\n",
        "\n",
        "# PREDICTION\n",
        "val_pred = classifier.predict(Val_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pg4IPf6Id3gv"
      },
      "outputs": [],
      "source": [
        "len(val_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7UWhuHFeJAT"
      },
      "outputs": [],
      "source": [
        "len(Val_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXMw3BJsejVW"
      },
      "outputs": [],
      "source": [
        "val_pred = val_pred.round().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_YxO0tWeo0T"
      },
      "outputs": [],
      "source": [
        "type(Val_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLN2Es4Leqpt"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98T-EJtodMdN"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy Score ->\",accuracy_score(val_pred, val_df.toxicity.values)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkcTMBbCd2iJ"
      },
      "outputs": [],
      "source": [
        "print(metrics.confusion_matrix(val_df.toxicity.values, val_pred, labels=[0, 1]))\n",
        "# Printing the precision and recall, among other metrics\n",
        "print(metrics.classification_report(val_df.toxicity.values, val_pred, labels=[0, 1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22fKTSdv1Qvr"
      },
      "outputs": [],
      "source": [
        "def predictSentence(inputArr):\n",
        "  testing_Sentences = []\n",
        "  for r in inputArr:\n",
        "    emb = use(r)\n",
        "    review_emb = tf.reshape(emb, [-1]).numpy()\n",
        "    testing_Sentences.append(review_emb)\n",
        "\n",
        "  testing_Sentences = np.array(testing_Sentences)\n",
        "\n",
        "  result = classifier.predict(testing_Sentences)\n",
        "  #print(type((result[0]*100).round().astype(int)))\n",
        "  print(\"The toxicity score for the sentence is: {} \".format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4MQnd7LhpyV"
      },
      "outputs": [],
      "source": [
        "inputArr = [\"I hate american people\"]\n",
        "predictSentence(inputArr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjAOObDQ2L7k"
      },
      "outputs": [],
      "source": [
        "inputArr = [\"I hate Black people\"]\n",
        "predictSentence(inputArr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0BhxxkT0Kgu"
      },
      "outputs": [],
      "source": [
        "inputArr = [\"I hate Asian people\"]\n",
        "predictSentence(inputArr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPS2go7M5xhi"
      },
      "outputs": [],
      "source": [
        "inputArr = [\"I hate Japanese people\"]\n",
        "predictSentence(inputArr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHZf7HQ55j6L"
      },
      "outputs": [],
      "source": [
        "inputArr = [\"I hate Korean people\"]\n",
        "predictSentence(inputArr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate Chinese people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "5xubAGfbq_yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate Finnish people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "DEr3n66prBMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate European people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "Oyp9SGQ7rDa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate American people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "VYPTKsBcrFjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate Indian people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "61bDC-a8rHQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate African people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "ooy0YeXtrIsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate Eastern people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "pVqHWiwSrKTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate Western people\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "u659vPLHrMK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate black\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "fYqmTT-wrNnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputArr = [\"I hate white\"]\n",
        "predictSentence(inputArr)"
      ],
      "metadata": {
        "id": "QwDdx7h2rO3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WdVJROXtrQQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cT-ZkQyRrSJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LightGBM Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}